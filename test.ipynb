{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "# for model customization\n",
    "from functools import partial\n",
    "from timm.models.vision_transformer import VisionTransformer, _cfg, Attention, Block\n",
    "from timm.models.layers import trunc_normal_\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04c39e3bcd34b76915611e761bceaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797969ba2f57469aa18bc046cb16a89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 459M/459M [00:54<00:00, 8.40MB/s] \n",
      "Downloading data: 100%|██████████| 526M/526M [03:50<00:00, 2.29MB/s] \n",
      "Downloading data: 100%|██████████| 468M/468M [03:08<00:00, 2.49MB/s] \n",
      "Downloading data: 100%|██████████| 452M/452M [02:53<00:00, 2.60MB/s] \n",
      "Downloading data: 100%|██████████| 469M/469M [03:50<00:00, 2.04MB/s] \n",
      "Downloading data: 100%|██████████| 478M/478M [03:33<00:00, 2.23MB/s] \n",
      "Downloading data: 100%|██████████| 441M/441M [03:38<00:00, 2.02MB/s] \n",
      "Downloading data: 100%|██████████| 420M/420M [03:03<00:00, 2.29MB/s] \n",
      "Downloading data: 100%|██████████| 437M/437M [02:56<00:00, 2.48MB/s] \n",
      "Downloading data: 100%|██████████| 438M/438M [03:53<00:00, 1.88MB/s] \n",
      "Downloading data: 100%|██████████| 440M/440M [03:24<00:00, 2.16MB/s] \n",
      "Downloading data: 100%|██████████| 439M/439M [03:32<00:00, 2.06MB/s] \n",
      "Downloading data: 100%|██████████| 429M/429M [03:02<00:00, 2.36MB/s] \n",
      "Downloading data: 100%|██████████| 480M/480M [03:32<00:00, 2.26MB/s] \n",
      "Downloading data: 100%|██████████| 479M/479M [03:24<00:00, 2.34MB/s] \n",
      "Downloading data: 100%|██████████| 376M/376M [02:56<00:00, 2.14MB/s] \n",
      "Downloading data: 100%|██████████| 512M/512M [03:32<00:00, 2.41MB/s] \n",
      "Downloading data: 100%|██████████| 505M/505M [03:48<00:00, 2.21MB/s] \n",
      "Downloading data: 100%|██████████| 497M/497M [03:46<00:00, 2.19MB/s] \n",
      "Downloading data: 100%|██████████| 465M/465M [03:02<00:00, 2.55MB/s] \n",
      "Downloading data: 100%|██████████| 416M/416M [02:54<00:00, 2.38MB/s] \n",
      "Downloading data: 100%|██████████| 413M/413M [02:53<00:00, 2.38MB/s] \n",
      "Downloading data: 100%|██████████| 428M/428M [02:57<00:00, 2.41MB/s] \n",
      "Downloading data: 100%|██████████| 418M/418M [02:36<00:00, 2.66MB/s] \n",
      "Downloading data: 100%|██████████| 422M/422M [03:20<00:00, 2.11MB/s] \n",
      "Downloading data: 100%|██████████| 404M/404M [02:54<00:00, 2.31MB/s] \n",
      "Downloading data: 100%|██████████| 409M/409M [02:46<00:00, 2.45MB/s] \n",
      "Downloading data: 100%|██████████| 409M/409M [02:58<00:00, 2.29MB/s] \n",
      "Downloading data: 100%|██████████| 425M/425M [02:54<00:00, 2.43MB/s] \n",
      "Downloading data: 100%|██████████| 430M/430M [03:03<00:00, 2.34MB/s] \n",
      "Downloading data: 100%|██████████| 412M/412M [02:55<00:00, 2.35MB/s] \n",
      "Downloading data: 100%|██████████| 379M/379M [02:54<00:00, 2.18MB/s] \n",
      "Downloading data: 100%|██████████| 423M/423M [03:21<00:00, 2.10MB/s] \n",
      "Downloading data: 100%|██████████| 433M/433M [02:58<00:00, 2.43MB/s] \n",
      "Downloading data: 100%|██████████| 379M/379M [02:45<00:00, 2.30MB/s] \n",
      "Downloading data:   5%|▍         | 21.0M/426M [00:09<02:43, 2.48MB/s]"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"evanarlian/imagenet_1k_resized_256\", cache_dir='/home/data/IMNET256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAttention(Attention):\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "        q, k = self.q_norm(q), self.k_norm(k)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = q @ k.transpose(-2, -1)\n",
    "        x = self.attn_drop(attn.softmax(dim=-1)) @ v\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x, attn\n",
    "\n",
    "class CustomBlock(Block):\n",
    "    def __init__(\n",
    "            self,\n",
    "            **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        for kw in ['mlp_ratio', 'init_values', 'drop_path', 'act_layer', 'mlp_layer']:\n",
    "            kwargs.pop(kw, None)\n",
    "        self.attn = CustomAttention(**kwargs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_, attn = self.attn(self.norm1(x))\n",
    "        x = x + self.drop_path1(self.ls1(x_))\n",
    "        x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))\n",
    "        return x, attn\n",
    "\n",
    "class DistillVisionTransformer(VisionTransformer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.dist_token = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.embed_dim))\n",
    "        self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if self.num_classes > 0 else nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.dist_token, std=.02)\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        self.head_dist.apply(self._init_weights)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        dist_token = self.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        attn = []\n",
    "        for blk in self.blocks:\n",
    "            x, a = blk(x)\n",
    "            attn.append(a)\n",
    "        attn = torch.stack(attn, dim=1)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0], x[:, 1], attn\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x_dist, attn = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        x_dist = self.head_dist(x_dist)\n",
    "        if self.training:\n",
    "            return x, x_dist, attn\n",
    "        else:\n",
    "            # during inference, return the average of both classifier predictions\n",
    "            return (x + x_dist) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.2489,  2.2489,  2.2489,  ...,  0.4627,  0.4338,  0.4080],\n",
       "          [ 2.2489,  2.2489,  2.2489,  ...,  0.5029,  0.5693,  0.5380],\n",
       "          [ 2.2489,  2.2489,  2.2489,  ...,  0.4870,  0.5354,  0.5178],\n",
       "          ...,\n",
       "          [-0.2145, -0.3301, -0.2220,  ...,  0.3099,  0.2612,  0.2527],\n",
       "          [-0.3632, -0.3537, -0.3418,  ...,  0.3785,  0.3223,  0.2573],\n",
       "          [-0.4371, -0.4600, -0.4058,  ...,  0.3983,  0.3611,  0.3098]],\n",
       " \n",
       "         [[ 2.4286,  2.4286,  2.4286,  ...,  0.9522,  0.9140,  0.8805],\n",
       "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0059,  1.0721,  1.0332],\n",
       "          [ 2.4286,  2.4286,  2.4286,  ...,  1.0157,  1.0479,  1.0408],\n",
       "          ...,\n",
       "          [-0.0699, -0.1919, -0.0840,  ...,  0.3000,  0.2713,  0.2705],\n",
       "          [-0.1953, -0.2136, -0.2055,  ...,  0.3539,  0.3318,  0.2793],\n",
       "          [-0.2881, -0.3253, -0.2683,  ...,  0.3613,  0.3356,  0.3166]],\n",
       " \n",
       "         [[ 2.6400,  2.6400,  2.6400,  ...,  0.1170,  0.1071,  0.1191],\n",
       "          [ 2.6400,  2.6400,  2.6400,  ...,  0.0991,  0.1439,  0.0778],\n",
       "          [ 2.6400,  2.6400,  2.6400,  ...,  0.0097,  0.0442,  0.0278],\n",
       "          ...,\n",
       "          [ 0.0432, -0.0844,  0.0239,  ...,  0.4774,  0.3978,  0.3309],\n",
       "          [-0.1095, -0.1330, -0.1537,  ...,  0.5349,  0.4561,  0.3160],\n",
       "          [-0.1938, -0.2354, -0.1869,  ...,  0.5480,  0.4878,  0.3664]]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ImageNetDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(type(self), self).__init__()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(256, interpolation=3, antialias=True),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "        ])\n",
    "\n",
    "        self.image_list = glob.glob('/home/data/imagenet_val/images/*.JPEG')\n",
    "        with open('/home/data/imagenet_val/imagenet_class_index.json') as fs:\n",
    "            self.label_dict = json.load(fs)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.image_list[index]\n",
    "\n",
    "        label = img.split('_')[-1].split('.')[0]\n",
    "        for k, v in self.label_dict.items():\n",
    "            if v[0] != label:\n",
    "                continue\n",
    "            label = torch.tensor([int(k)])\n",
    "            label = nn.functional.one_hot(label, 1000).float().view(-1)\n",
    "            break\n",
    "\n",
    "        img = cv2.imread(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "dataset = ImageNetDataset()\n",
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {0:[], 1:[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "deit_small_distilled_patch16_224 = DistillVisionTransformer(\n",
    "    block_fn=CustomBlock, patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6))\n",
    "deit_small_distilled_patch16_224.default_cfg = _cfg()\n",
    "\n",
    "dataset = ImageNetDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "optimizer = torch.optim.Adam(deit_small_distilled_patch16_224.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 56/3125 [00:17<16:21,  3.13it/s, loss=7.2] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m out_c, out_s, attn \u001b[38;5;241m=\u001b[39m \u001b[43mdeit_small_distilled_patch16_224\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m loss_cls \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(out_c, label)\n\u001b[1;32m     11\u001b[0m history[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss_cls\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 68\u001b[0m, in \u001b[0;36mDistillVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 68\u001b[0m     x, x_dist, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n\u001b[1;32m     70\u001b[0m     x_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dist(x_dist)\n",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m, in \u001b[0;36mDistillVisionTransformer.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m attn \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 60\u001b[0m     x, a \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     attn\u001b[38;5;241m.\u001b[39mappend(a)\n\u001b[1;32m     62\u001b[0m attn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(attn, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m, in \u001b[0;36mCustomBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 29\u001b[0m     x_, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls1(x_))\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))))\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mCustomAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m q, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_norm(q), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_norm(k)\n\u001b[1;32m      9\u001b[0m q \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[0;32m---> 10\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m@\u001b[39m v\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, N, C)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deit_small_distilled_patch16_224.to(device)\n",
    "deit_small_distilled_patch16_224.train()\n",
    "\n",
    "tq = tqdm.tqdm(dataloader)\n",
    "for i, (img, label) in enumerate(tq):\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    out_c, out_s, attn = deit_small_distilled_patch16_224(img)\n",
    "    loss_cls = nn.functional.cross_entropy(out_c, label)\n",
    "    history[0].append(loss_cls.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_cls.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    tq.set_postfix(loss=loss_cls.item())\n",
    "    if (i+1) == 500:\n",
    "        break\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "deit_small_patch16_224 = VisionTransformer(\n",
    "    patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "    norm_layer=partial(nn.LayerNorm, eps=1e-6))\n",
    "deit_small_patch16_224.default_cfg = _cfg()\n",
    "checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            url=\"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\",\n",
    "            map_location=\"cpu\", check_hash=True\n",
    "        )\n",
    "deit_small_patch16_224.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "#model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "deit_small_distilled_patch16_224 = DistillVisionTransformer(\n",
    "    block_fn=CustomBlock, patch_size=16, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6))\n",
    "deit_small_distilled_patch16_224.default_cfg = _cfg()\n",
    "\n",
    "dataset = ImageNetDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "optimizer = torch.optim.Adam(deit_small_distilled_patch16_224.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3125 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "HIP out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 11.98 GiB of which 124.00 MiB is free. Of the allocated memory 10.93 GiB is allocated by PyTorch, and 518.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m out_c, out_s, attn \u001b[38;5;241m=\u001b[39m \u001b[43mdeit_small_distilled_patch16_224\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m out_t \u001b[38;5;241m=\u001b[39m deit_small_patch16_224(img)\n\u001b[1;32m     16\u001b[0m loss_cls \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(out_c, label)\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 68\u001b[0m, in \u001b[0;36mDistillVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 68\u001b[0m     x, x_dist, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n\u001b[1;32m     70\u001b[0m     x_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dist(x_dist)\n",
      "Cell \u001b[0;32mIn[2], line 62\u001b[0m, in \u001b[0;36mDistillVisionTransformer.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m     x, a \u001b[38;5;241m=\u001b[39m blk(x)\n\u001b[1;32m     61\u001b[0m     attn\u001b[38;5;241m.\u001b[39mappend(a)\n\u001b[0;32m---> 62\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x[:, \u001b[38;5;241m0\u001b[39m], x[:, \u001b[38;5;241m1\u001b[39m], attn\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: HIP out of memory. Tried to allocate 346.00 MiB. GPU 0 has a total capacty of 11.98 GiB of which 124.00 MiB is free. Of the allocated memory 10.93 GiB is allocated by PyTorch, and 518.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "deit_small_patch16_224.to(device)\n",
    "deit_small_patch16_224.eval()\n",
    "\n",
    "deit_small_distilled_patch16_224.to(device)\n",
    "deit_small_distilled_patch16_224.train()\n",
    "\n",
    "alpha = 0.9\n",
    "\n",
    "tq = tqdm.tqdm(dataloader)\n",
    "for i, (img, label) in enumerate(tq):\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    out_c, out_s, attn = deit_small_distilled_patch16_224(img)\n",
    "    out_t = deit_small_patch16_224(img)\n",
    "    loss_cls = nn.functional.cross_entropy(out_c, label)\n",
    "    loss_dist = nn.functional.kl_div(out_c, out_t, reduction='batchmean', log_target=True)\n",
    "    loss = alpha * loss_cls + (1 - alpha) * loss_dist\n",
    "    history[1].append(loss_cls.item())\n",
    "    break\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    tq.set_postfix(loss=loss_cls.item())\n",
    "    if (i+1) == 100:\n",
    "        break\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stochastic_mask_selection(attn, t, k):\n",
    "    '''\n",
    "    attn: shape (N,N) for N patches\n",
    "    t: soften temperature\n",
    "    k: keep number\n",
    "    '''\n",
    "    attn = torch.softmax(attn.sum(dim=1)/t, dim=0).cumsum(dim=0)\n",
    "    keep = attn.multinomial(num_samples=k, replacement=False)\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
